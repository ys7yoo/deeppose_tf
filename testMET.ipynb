{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter notebook for testing an image\n",
    "\n",
    "Code from [tests/test_snapshot.py](tests/test_snapshot.py)\n",
    "\n",
    "required packages \n",
    "\n",
    "1. Tensorflow\n",
    "\n",
    "2. Other packages\n",
    "```\n",
    "pip install tqdm chainer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from scripts import dataset\n",
    "import scripts.regressionnet\n",
    "from scripts.regressionnet import batch2feeds, calculate_metric\n",
    "\n",
    "\n",
    "from scripts import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:00, 122.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/data/MET2/activity.csv\n",
      "/var/data/MET2\n",
      "Reading dataset from /var/data/MET2/activity.csv\n",
      "Downscale images to the height 400px\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:00, 97.74it/s] /home/yyoo/src/deeppose/scripts/dataset.py:136: UserWarning: Skipping joint with incorrect joints coordinates. They are out of the image.\n",
      "image: /var/data/MET2/image/office activities/walking about/31.png, joint: [273.58708189 546.71280277], im.shape: (400, 185)\n",
      "  'image: {}, joint: {}, im.shape: {}'.format(img_path, joints[i_joint], image_shape[:2]))\n",
      "54it [00:00, 82.63it/s]/home/yyoo/src/deeppose/scripts/dataset.py:136: UserWarning: Skipping joint with incorrect joints coordinates. They are out of the image.\n",
      "image: /var/data/MET2/image/office activities/walking about/59.jpg, joint: [112.72727273 538.18181818], im.shape: (400, 267)\n",
      "  'image: {}, joint: {}, im.shape: {}'.format(img_path, joints[i_joint], image_shape[:2]))\n",
      "330it [00:02, 144.32it/s]/home/yyoo/src/deeppose/scripts/dataset.py:136: UserWarning: Skipping joint with incorrect joints coordinates. They are out of the image.\n",
      "image: /var/data/MET2/image/office activities/lifting.packing/packing/41.png, joint: [421. 779.], im.shape: (328, 622)\n",
      "  'image: {}, joint: {}, im.shape: {}'.format(img_path, joints[i_joint], image_shape[:2]))\n",
      "588it [00:03, 157.56it/s]/home/yyoo/src/deeppose/scripts/dataset.py:136: UserWarning: Skipping joint with incorrect joints coordinates. They are out of the image.\n",
      "image: /var/data/MET2/image/miscellaneous occupational activity/house cleaning/58.jpg, joint: [228.79078695 742.4184261 ], im.shape: (400, 599)\n",
      "  'image: {}, joint: {}, im.shape: {}'.format(img_path, joints[i_joint], image_shape[:2]))\n",
      "756it [00:04, 166.09it/s]/home/yyoo/src/deeppose/scripts/dataset.py:136: UserWarning: Skipping joint with incorrect joints coordinates. They are out of the image.\n",
      "image: /var/data/MET2/image/resting/reclining/59.jpg, joint: [316.          64.61538462], im.shape: (400, 266)\n",
      "  'image: {}, joint: {}, im.shape: {}'.format(img_path, joints[i_joint], image_shape[:2]))\n",
      "/home/yyoo/src/deeppose/scripts/dataset.py:136: UserWarning: Skipping joint with incorrect joints coordinates. They are out of the image.\n",
      "image: /var/data/MET2/image/resting/reclining/9.png, joint: [ 78. 153.], im.shape: (137, 326)\n",
      "  'image: {}, joint: {}, im.shape: {}'.format(img_path, joints[i_joint], image_shape[:2]))\n",
      "960it [00:04, 192.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joints shape: (14, 2)\n",
      "data ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# this was main function\n",
    "dataset_name = 'met'\n",
    "\n",
    "if dataset_name not in ['met', 'lsp', 'mpii']:\n",
    "    raise ValueError('Unknown dataset: {}'.format(dataset_name))\n",
    "\n",
    "if dataset_name == 'mpii':\n",
    "    TEST_CV_FILEPATH = os.path.join(config.MPII_DATASET_ROOT, 'test_joints.csv')\n",
    "    IMG_PATH_PREFIX = os.path.join(config.MPII_DATASET_ROOT, 'images')\n",
    "    symmetric_joints = \"[[12, 13], [11, 14], [10, 15], [2, 3], [1, 4], [0, 5]]\"\n",
    "    ignore_label = -100500\n",
    "elif dataset_name == 'lsp': # LSP dataset\n",
    "    TEST_CV_FILEPATH = os.path.join(config.LSP_DATASET_ROOT, 'test_joints.csv')\n",
    "    IMG_PATH_PREFIX = os.path.join(config.LSP_DATASET_ROOT, 'images')\n",
    "    symmetric_joints = \"[[8, 9], [7, 10], [6, 11], [2, 3], [1, 4], [0, 5]]\"\n",
    "    ignore_label = -1\n",
    "elif dataset_name == 'met': # MET dataset\n",
    "    #TEST_CV_FILEPATH = os.path.join(config.MET_DATASET_ROOT, 'activity1.csv') # test only one image\n",
    "    TEST_CV_FILEPATH = os.path.join(config.MET_DATASET_ROOT, 'activity.csv')\n",
    "    IMG_PATH_PREFIX = os.path.join(config.MET_DATASET_ROOT)\n",
    "    symmetric_joints = \"[[8, 9], [7, 10], [6, 11], [2, 3], [1, 4], [0, 5]]\"\n",
    "    ignore_label = -1\n",
    "else:\n",
    "    pass\n",
    " \n",
    "    \n",
    "print(TEST_CV_FILEPATH)\n",
    "print(IMG_PATH_PREFIX)\n",
    "\n",
    "test_dataset = dataset.PoseDataset(\n",
    "    TEST_CV_FILEPATH,\n",
    "    IMG_PATH_PREFIX, 227,\n",
    "    fliplr=False, rotate=False,\n",
    "    shift=None,\n",
    "    bbox_extension_range=(1.0, 1.0),\n",
    "    coord_normalize=True,\n",
    "    gcn=True,\n",
    "    fname_index=0,\n",
    "    joint_index=1,\n",
    "    symmetric_joints=symmetric_joints,\n",
    "    ignore_label=ignore_label,\n",
    "    should_return_bbox=True,\n",
    "    should_downscale_images=True,\n",
    "    downscale_height=400\n",
    ")\n",
    "\n",
    "print(\"data ready\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexnet::__create_architecture()\n",
      "Initializing conv1 with random\n",
      "Initializing conv2 with random\n",
      "Initializing conv3 with random\n",
      "Initializing conv4 with random\n",
      "Initializing conv5 with random\n",
      "Initializing fc6 with random\n",
      "Initializing fc7 with random\n",
      "Initializing fc8 with random\n",
      "Initializing layer 99 with random\n",
      "Restoring everything from snapshot and resuming from /var/data/out/lsp_alexnet_imagenet/checkpoint-1000000\n",
      "INFO:tensorflow:Restoring parameters from /var/data/out/lsp_alexnet_imagenet/checkpoint-1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/data/out/lsp_alexnet_imagenet/checkpoint-1000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating optimizer momentum\n",
      "Conv LR: Tensor(\"lr/conv_lr:0\", shape=(), dtype=float32), FC LR: Tensor(\"lr/fc_lr:0\", shape=(), dtype=float32)\n",
      "INFO:tensorflow:Summary name grad_norms/conv1/weight:0 is illegal; using grad_norms/conv1/weight_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/conv1/weight:0 is illegal; using grad_norms/conv1/weight_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/conv1/bias:0 is illegal; using grad_norms/conv1/bias_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/conv1/bias:0 is illegal; using grad_norms/conv1/bias_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/conv2/weight:0 is illegal; using grad_norms/conv2/weight_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/conv2/weight:0 is illegal; using grad_norms/conv2/weight_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/conv2/bias:0 is illegal; using grad_norms/conv2/bias_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/conv2/bias:0 is illegal; using grad_norms/conv2/bias_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/conv3/weight:0 is illegal; using grad_norms/conv3/weight_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/conv3/weight:0 is illegal; using grad_norms/conv3/weight_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/conv3/bias:0 is illegal; using grad_norms/conv3/bias_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/conv3/bias:0 is illegal; using grad_norms/conv3/bias_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/conv4/weight:0 is illegal; using grad_norms/conv4/weight_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/conv4/weight:0 is illegal; using grad_norms/conv4/weight_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/conv4/bias:0 is illegal; using grad_norms/conv4/bias_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/conv4/bias:0 is illegal; using grad_norms/conv4/bias_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/conv5/weight:0 is illegal; using grad_norms/conv5/weight_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/conv5/weight:0 is illegal; using grad_norms/conv5/weight_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/conv5/bias:0 is illegal; using grad_norms/conv5/bias_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/conv5/bias:0 is illegal; using grad_norms/conv5/bias_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/fc6/weight:0 is illegal; using grad_norms/fc6/weight_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/fc6/weight:0 is illegal; using grad_norms/fc6/weight_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/fc6/bias:0 is illegal; using grad_norms/fc6/bias_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/fc6/bias:0 is illegal; using grad_norms/fc6/bias_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/fc7/weight:0 is illegal; using grad_norms/fc7/weight_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/fc7/weight:0 is illegal; using grad_norms/fc7/weight_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/fc7/bias:0 is illegal; using grad_norms/fc7/bias_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/fc7/bias:0 is illegal; using grad_norms/fc7/bias_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/fc_regression/weight:0 is illegal; using grad_norms/fc_regression/weight_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/fc_regression/weight:0 is illegal; using grad_norms/fc_regression/weight_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/fc_regression/bias:0 is illegal; using grad_norms/fc_regression/bias_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name grad_norms/fc_regression/bias:0 is illegal; using grad_norms/fc_regression/bias_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uninit vars: ['conv1/weight/Momentum:0', 'conv1/bias/Momentum:0', 'conv2/weight/Momentum:0', 'conv2/bias/Momentum:0', 'conv3/weight/Momentum:0', 'conv3/bias/Momentum:0', 'conv4/weight/Momentum:0', 'conv4/bias/Momentum:0', 'conv5/weight/Momentum:0', 'conv5/bias/Momentum:0', 'fc6/weight/Momentum:0', 'fc6/bias/Momentum:0', 'fc7/weight/Momentum:0', 'fc7/bias/Momentum:0', 'fc_regression/weight/Momentum:0', 'fc_regression/bias/Momentum:0']\n",
      "Elapsed time for finding uninitialized variables: 0.67s\n",
      "Elapsed time to init them: 0.25s\n",
      "<scripts.alexnet.Alexnet object at 0x7f7ba8ed4c88>\n",
      "/var/data/out/lsp_alexnet_imagenet/checkpoint-1000000\n"
     ]
    }
   ],
   "source": [
    "# load creat regressionnet and load weight from snapshot \n",
    "\n",
    "snapshot_path = '/var/data/out/lsp_alexnet_imagenet/checkpoint-1000000'\n",
    "# init_snapshot_path = os.path.join(config.ROOT_DIR, 'out/mpii_alexnet_imagenet/checkpoint-10000')\n",
    "# init_snapshot_path = os.path.join(config.ROOT_DIR, 'out/lsp_alexnet_scratch/checkpoint-10000')\n",
    "\n",
    "from scripts import regressionnet\n",
    "\n",
    "net, loss_op, pose_loss_op, train_op = regressionnet.create_regression_net(\n",
    "    n_joints=16 if dataset_name == 'mpii' else 14,\n",
    "    init_snapshot_path=snapshot_path,\n",
    "    is_resume=True,\n",
    "    net_type='Alexnet',\n",
    "    optimizer_type='momentum',\n",
    "    gpu_memory_fraction=0.32)  # Set how much GPU memory to reserve for the network\n",
    "\n",
    "print(net)\n",
    "print(snapshot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"start testing\")\n",
    "\n",
    "# predict joints\n",
    "batch_size=128\n",
    "avg_loss, global_step, gt_joints, gt_joints_is_valid, predicted_joints, orig_bboxes = regressionnet.predict(net, pose_loss_op, test_dataset, batch_size, summary_writer=None, dataset_name=dataset_name, tag_prefix='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(gt_joints.shape)\n",
    "print(gt_joints)\n",
    "print(predicted_joints.shape)\n",
    "print(predicted_joints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = gt_joints[0][:,0]\n",
    "xhat = predicted_joints[0][:,0]\n",
    "y = gt_joints[0][:,1]\n",
    "yhat = predicted_joints[0][:,1]\n",
    "\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(x,xhat,'.')\n",
    "plt.xlabel('x');plt.ylabel('xHat');\n",
    "plt.plot([min(x), max(x)], [min(x), max(x)],'--')\n",
    "plt.subplot(122)\n",
    "plt.plot(y,yhat,'.')\n",
    "plt.plot([min(y), max(y)], [min(y), max(y)],'--')\n",
    "plt.xlabel('y');plt.ylabel('yHat');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predicted joints coordination to prectedJointsMET_1000_14.txt\n",
    "n, numJoints, dim = predicted_joints.shape\n",
    "np.savetxt('prectedJointsMET_{}_{}.txt'.format(n,numJoints),predicted_joints.reshape(-1,numJoints*dim), delimiter=',')\n",
    "\n",
    "# TODO: convert to image coordinate before saving!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_ori = test_dataset.images['image/office activities/walking about/1.png']\n",
    "#?test_dataset\n",
    "#test_dataset.get_example(0)\n",
    "image, joints, is_valid_joints, misc = test_dataset.get_example(0)\n",
    "\n",
    "# plot\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(image_ori[:,:,::-1], interpolation = 'bicubic')\n",
    "plt.subplot(122)\n",
    "plt.imshow(image[:,:,::-1], interpolation = 'bicubic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer import iterators\n",
    "test_it = iterators.MultiprocessIterator(test_dataset, batch_size=batch_size,\n",
    "                                             repeat=False, shuffle=False,\n",
    "                                             n_processes=1, n_prefetch=1)\n",
    "    # http://docs.chainer.org/en/stable/reference/generated/chainer.iterators.MultiprocessIterator.html\n",
    "\n",
    "for i, batch in enumerate(test_it):\n",
    "    print(batch[0][0].shape)\n",
    "    print(batch[0][1].shape)\n",
    "    print(batch[0][2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check image size\n",
    "# img = test_dataset.images['image/office activities/walking about/1.png']\n",
    "# print(img.shape)\n",
    "# j = test_dataset.joints\n",
    "# print(j)\n",
    "\n",
    "\n",
    "# plot one image from the data\n",
    "imageIdx = 0\n",
    "\n",
    "\n",
    "img=test_dataset.get_original_image(imageIdx)\n",
    "h,w,d=img.shape\n",
    "print(h,w,d)  # 169 95 3\n",
    "\n",
    "# joints has all the info loaded from test_joints.csv\n",
    "img_id, joints = test_dataset.joints[imageIdx]\n",
    "print(img_id)  # /var/data/lsp/images/im1001.jpg\n",
    "print(joints)  # [[ 42.96321929 138.35880369]\n",
    "\n",
    "\n",
    "#print(test_dataset.images)\n",
    "img, joints, is_valid_joints, misc = test_dataset.get_example(imageIdx)\n",
    "h,w,d=img.shape\n",
    "print(h,w,d)   # 227 227 3\n",
    "print(joints)  # [[-0.06828195  0.42070484]\n",
    "\n",
    "#print(test_dataset[imageIdx][0].shape)\n",
    "#print(test_dataset[imageIdx][1].shape)\n",
    "#print(test_dataset[imageIdx][2].shape)\n",
    "\n",
    "\n",
    "# calc PCP\n",
    "for ext in np.linspace(1.0, 2.0, 6, True):\n",
    "    print('\\n====================')\n",
    "    print('BBOX EXTENSION:', ext)\n",
    "    test_dataset.bbox_extension_range = (ext, ext)\n",
    "    \n",
    "\n",
    "    # calc metric\n",
    "    scripts.regressionnet.calc_pcp(global_step, gt_joints, gt_joints_is_valid, predicted_joints, orig_bboxes, dataset_name)\n",
    "        \n",
    "    \"\"\"\n",
    "    scripts.regressionnet.evaluate_pcp(net, pose_loss_op, test_iterator, None,\n",
    "                                       dataset_name=dataset_name,\n",
    "                                       tag_prefix='test')\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict one image \n",
    "from cv2 import imread, resize\n",
    "\n",
    "# load an image  (code from load_images in scripts/dataset.py)\n",
    "img_path='/var/data/MET2/image/office activities/walking about/1.png'\n",
    "image = imread(img_path)  # HWC BGR image\n",
    "print(image.shape)\n",
    "#downscale image if needed\n",
    "downscale_height = 400\n",
    "if image.shape[0] > downscale_height:\n",
    "    downscale_factor = float(image.shape[0]) / self.downscale_height\n",
    "    image = resize(image, None, fx=1.0/downscale_factor, fy=1.0/downscale_factor)\n",
    "                \n",
    "\n",
    "\n",
    "# code from predict in scripts/regressionnet.py\n",
    "\n",
    "feed_dict = {\n",
    "        net.x: image,   # should be in the shape of (?, 227, 227, 3)\n",
    "        #'pose_input/joints_gt:0': joints_gt,\n",
    "        #'pose_input/joints_is_valid:0': joints_is_valid,\n",
    "        'input/is_phase_train:0': False,   # testing!\n",
    "        'lr/conv_lr:0': 0.0,\n",
    "        'lr/fc_lr:0': 0.0\n",
    "    }\n",
    "\n",
    "pred_j, batch_loss_value = net.sess.run([net.fc_regression, pose_loss_op], feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from regressionnet.fill_joint_feed_dict\n",
    "def fill_joint_feed_dict(net, batch_feeds,\n",
    "                         conv_lr=None, fc_lr=None,\n",
    "                         phase='test', train_keep_prob=0.4):\n",
    "    \"\"\"Fills the feed_dict for training the given step.\n",
    "\n",
    "    A feed_dict takes the form of:\n",
    "    feed_dict = {\n",
    "        <placeholder>: <tensor of values to be passed for placeholder>,\n",
    "        ....\n",
    "    }\n",
    "\n",
    "    Args:\n",
    "      batch_loader: BatchLoader, that provides batches of the data\n",
    "      images_pl: The images placeholder, from placeholder_inputs().\n",
    "      labels_pl: The labels placeholder, from placeholder_inputs().\n",
    "\n",
    "    Returns:\n",
    "      feed_dict: The feed dictionary mapping from placeholders to values.\n",
    "    \"\"\"\n",
    "    if phase not in ['train', 'test']:\n",
    "        raise ValueError('phase must be \"train\" or \"test\"')\n",
    "    if phase == 'train':\n",
    "        keep_prob = train_keep_prob\n",
    "        is_phase_train = True\n",
    "    else:\n",
    "        keep_prob = 1.0\n",
    "        is_phase_train = False\n",
    "\n",
    "    if len(batch_feeds) != 3:\n",
    "        raise ValueError('feeds must contain only 3 elements: images, joints_gt, joints_is_valid')\n",
    "    images, joints_gt, joints_is_valid = batch_feeds\n",
    "\n",
    "    feed_dict = {\n",
    "        net.x: images,\n",
    "        'pose_input/joints_gt:0': joints_gt,\n",
    "        'pose_input/joints_is_valid:0': joints_is_valid,\n",
    "        'input/is_phase_train:0': is_phase_train,\n",
    "        'lr/conv_lr:0': conv_lr,\n",
    "        'lr/fc_lr:0': fc_lr\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        keep_prob_pl = net.graph.get_tensor_by_name('input/dropout_keep_prob:0')\n",
    "        dropout_params = {keep_prob_pl: keep_prob}\n",
    "    except KeyError:\n",
    "        dropout_params = {'fc6/keep_prob_pl:0': keep_prob,\n",
    "                          'fc7/keep_prob_pl:0': keep_prob}\n",
    "    feed_dict.update(dropout_params)\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from regressionnet.evaluate_pcp\n",
    "summary_writer = None\n",
    "tag_prefix='test'\n",
    "\n",
    "total_loss = 0.0\n",
    "\n",
    "num_joints = int(int(net.fc_regression.get_shape()[1]) / 2)\n",
    "gt_joints = list()\n",
    "gt_joints_is_valid = list()\n",
    "predicted_joints = list()\n",
    "orig_bboxes = list()\n",
    "    \n",
    "\n",
    "test_it = copy.copy(test_iterator)\n",
    "num_test_examples = len(test_it.dataset)\n",
    "num_batches = int(math.ceil(num_test_examples / test_it.batch_size))\n",
    "for i, batch in tqdm(enumerate(test_it), total=num_batches):\n",
    "\n",
    "        # uncomment a breakpoint here for debugging\n",
    "        # import pdb; pdb.set_trace()\n",
    "\n",
    "        feeds = batch2feeds(batch)\n",
    "        feed_dict = fill_joint_feed_dict(net,\n",
    "                                         feeds[:3],\n",
    "                                         conv_lr=0.0,\n",
    "                                         fc_lr=0.0,\n",
    "                                         phase='test')\n",
    "\n",
    "        pred_j, batch_loss_value = net.sess.run([net.fc_regression, pose_loss_op], feed_dict=feed_dict)\n",
    "        total_loss += batch_loss_value * len(batch)\n",
    "        predicted_joints.append(pred_j.reshape(-1, num_joints, 2))\n",
    "\n",
    "        gt_joints.append(feeds[1])\n",
    "        gt_joints_is_valid.append(feeds[2])\n",
    "        orig_bboxes.append(np.vstack([x['bbox'] for x in feeds[3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimated joints\n",
    "imageIdx = 0\n",
    "print(predicted_joints[imageIdx][0].shape)\n",
    "print(predicted_joints[imageIdx][0])\n",
    "xhat = predicted_joints[imageIdx][0][:,0]\n",
    "yhat = predicted_joints[imageIdx][0][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# plot example image (normalized)\n",
    "img, joints, is_valid_joints, misc = test_dataset.get_example(imageIdx, gcn=None, bbox_extension_range=None, shift=None)\n",
    "print(joints)\n",
    "\n",
    "#img = test_dataset.get_original_image(imageIdx)  # 169 95 3\n",
    "\n",
    "\n",
    "h,w,d=img.shape\n",
    "print(h,w,d)    # 227 227 3\n",
    "\n",
    "x = joints[:,0]\n",
    "print([min(x), max(x)])\n",
    "y = joints[:,1]\n",
    "print([min(y), max(y)])\n",
    "\n",
    "#cv2.imshow('image',img)\n",
    "#if cv2.waitKey(10) & 0xFF == 27:\n",
    "#        print(\"quit\")\n",
    "#        break\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.plot(x,xhat,'.')\n",
    "plt.xlabel('x');plt.ylabel('xHat');\n",
    "plt.plot([min(x), max(x)], [min(x), max(x)],'--')\n",
    "plt.subplot(122)\n",
    "plt.plot(y,yhat,'.')\n",
    "plt.plot([min(y), max(y)], [min(y), max(y)],'--')\n",
    "plt.xlabel('y');plt.ylabel('yHat');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotJoints(img, joints, color=(255,255,255)):\n",
    "    img = img.copy()\n",
    "    numJoints, t = joints.shape\n",
    "    #numJoints, t = predicted_joints[0].shape #joints.shape\n",
    "    #print(numJoints,t)\n",
    "\n",
    "    circSize=10\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    #cv2.drawKeypoints(img,joints,img)\n",
    "    for i in range(numJoints):\n",
    "        #print(joints[i,:])\n",
    "        x = joints[i,0]\n",
    "        y = joints[i,1]\n",
    "        #x = predicted_joints[0][0][i,0]\n",
    "        #y = predicted_joints[0][0][i,1]\n",
    "\n",
    "        # transform \n",
    "        xx = int(w/2 + w*x)\n",
    "        yy = int(h/2 + h*y)    \n",
    "        #print(x,y)\n",
    "\n",
    "        cv2.circle(img, (xx, yy), 5, color) #, -1)\n",
    "\n",
    "        cv2.putText(img, str(i+1), (xx,yy), font, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "    #    cv2.text(img, (x, y), 5, (255, 0, 0)) #, -1)\n",
    "        # https://docs.opencv.org/3.1.0/dc/da5/tutorial_py_drawing_functions.html\n",
    "    \n",
    "    return img \n",
    "\n",
    "plt.subplot(121)\n",
    "img1=plotJoints(img,joints, (255,0,0))\n",
    "plt.imshow(img1[:,:,::-1], interpolation = 'bicubic')\n",
    "#plt.imshow(img[:,:,0], cmap='gray', interpolation = 'bicubic')\n",
    "\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "\n",
    "plt.subplot(122)\n",
    "plotJoints(img, predicted_joints[imageIdx][0])\n",
    "#plt.imshow(img[:,:,::-1], cmap = 'gray', interpolation = 'bicubic')\n",
    "plt.imshow(img[:,:,0], cmap = 'gray', interpolation = 'bicubic')\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(img, vmin = -2, vmax = 2)\n",
    "#plt.show()\n",
    "print(img.shape)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "ax.imshow(img, cmap='gray', vmin = -2, vmax = 2, interpolation = 'bicubic')\n",
    "#ax.autoscale(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(img*0.5)\n",
    "I = np.minimum(np.maximum(img*0.5,-1),1)\n",
    "print(I)\n",
    "\n",
    "from skimage import data, io, filters\n",
    "io.imshow(I)\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example to get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_iterator)\n",
    "test_iterator = iterators.MultiprocessIterator(\n",
    "    test_dataset, batch_size=128,\n",
    "    repeat=False, shuffle=False,\n",
    "    n_processes=1, n_prefetch=1)\n",
    "# http://docs.chainer.org/en/stable/reference/generated/chainer.iterators.MultiprocessIterator.html\n",
    "\n",
    "for i, batch in enumerate(test_iterator): \n",
    "    print(i, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gt_data(test_iterator):\n",
    "    test_it = copy.copy(test_iterator)\n",
    "    num_test_examples = len(test_it.dataset)\n",
    "    num_batches = int(math.ceil(num_test_examples / test_it.batch_size))\n",
    "    gt_joints = list()\n",
    "    gt_joints_is_valid = list()\n",
    "    orig_bboxes = list()\n",
    "\n",
    "    print(len(test_it.dataset))\n",
    "    for i, batch in tqdm(enumerate(test_it), total=num_batches):\n",
    "        feeds = batch2feeds(batch)\n",
    "        gt_joints.append(feeds[1])\n",
    "        gt_joints_is_valid.append(feeds[2])\n",
    "        orig_bboxes.append(np.vstack([x['bbox'] for x in feeds[3]]))\n",
    "\n",
    "    gt_joints = np.vstack(gt_joints)\n",
    "    gt_joints_is_valid = np.vstack(gt_joints_is_valid)\n",
    "    orig_bboxes = np.vstack(orig_bboxes)\n",
    "    return gt_joints, gt_joints_is_valid, orig_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iterator = iterators.MultiprocessIterator(\n",
    "    test_dataset, batch_size=128,\n",
    "    repeat=False, shuffle=False,\n",
    "    n_processes=1, n_prefetch=1)\n",
    "# http://docs.chainer.org/en/stable/reference/generated/chainer.iterators.MultiprocessIterator.html\n",
    "\n",
    "gt_joints, gt_joints_is_valid, orig_bboxes = get_gt_data(test_iterator)\n",
    "\n",
    "print(gt_joints.shape)\n",
    "print(gt_joints_is_valid.shape)\n",
    "print(orig_bboxes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
